{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1197da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sn\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, Dropout\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc25839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clean_az_brown2.txt\", 'r', encoding='utf-8') as f:\n",
    "    s2 = f.read().splitlines()\n",
    "s3 = [re.sub('\\n', '', sentence) for sentence in s2]    \n",
    "tagged_sentences = [sentence.split(\" \") for sentence in s3]\n",
    "corpus = [[tuple(word.split(\"/\")) for word in sentence] for sentence in tagged_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a168a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # store input sequence\n",
    "Y = [] # store output sequence\n",
    "\n",
    "for sentence in corpus:\n",
    "    X_sentence = []\n",
    "    Y_sentence = []\n",
    "    for entity in sentence:         \n",
    "        X_sentence.append(entity[0])  # entity[0] contains the word\n",
    "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
    "        \n",
    "    X.append(X_sentence)\n",
    "    Y.append(Y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f68c76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample X:  ['Həkan-həkan', 'içində', ',', 'qoz', 'girdəkan', 'içində', ',', 'dəvə', 'dəlləklik', 'elər', ',', 'köhnə', 'hamam', 'içində', '.'] \n",
      "\n",
      "sample Y:  ['Isim', 'Zərf', ',', 'Isim', 'Isim', 'Zərf', ',', 'Isim', 'Isim', 'Fel', ',', 'Sifət', 'Isim', 'Zərf', 'Durğu_işarəsi'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at first data point\n",
    "# this is one data point that will be fed to the RNN\n",
    "print('sample X: ', X[0], '\\n')\n",
    "print('sample Y: ', Y[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1f29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
    "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507af007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tagged sentences: 1806\n",
      "Vocabulary size: 6644\n",
      "Total number of tags: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
    "print(\"Vocabulary size: {}\".format(num_words))\n",
    "print(\"Total number of tags: {}\".format(num_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d179c673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first input sequence  : 15\n",
      "Length of first output sequence : 15\n"
     ]
    }
   ],
   "source": [
    "# In this many-to-many problem, the length of each input and output sequence must be the same.\n",
    "# Since each word is tagged, it's important to make sure that the length of input sequence equals the output sequence\n",
    "print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
    "print(\"Length of first output sequence : {}\".format(len(Y[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a98a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode X\n",
    "\n",
    "word_tokenizer = Tokenizer()                      # instantiate tokeniser\n",
    "word_tokenizer.fit_on_texts(X)                    # fit tokeniser on data\n",
    "X_encoded = word_tokenizer.texts_to_sequences(X)  # use the tokeniser to encode input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa1bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Y\n",
    "\n",
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(Y)\n",
    "Y_encoded = tag_tokenizer.texts_to_sequences(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d7c335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Raw data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  ['Həkan-həkan', 'içində', ',', 'qoz', 'girdəkan', 'içində', ',', 'dəvə', 'dəlləklik', 'elər', ',', 'köhnə', 'hamam', 'içində', '.'] \n",
      "\n",
      "Y:  ['Isim', 'Zərf', ',', 'Isim', 'Isim', 'Zərf', ',', 'Isim', 'Isim', 'Fel', ',', 'Sifət', 'Isim', 'Zərf', 'Durğu_işarəsi'] \n",
      "\n",
      "\n",
      "** Encoded data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  [2106, 225, 2, 765, 1195, 225, 2, 2107, 2108, 2109, 2, 351, 2110, 225, 1] \n",
      "\n",
      "Y:  [1, 7, 6, 1, 1, 7, 6, 1, 1, 2, 6, 5, 1, 7, 3] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at first encoded data point\n",
    "\n",
    "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X[0], '\\n')\n",
    "print('Y: ', Y[0], '\\n')\n",
    "print()\n",
    "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X_encoded[0], '\\n')\n",
    "print('Y: ', Y_encoded[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2c7de72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sentences have disparate input-output lengths.\n"
     ]
    }
   ],
   "source": [
    "# make sure that each sequence of input and output is same length\n",
    "\n",
    "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_encoded, Y_encoded)]\n",
    "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f545d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest sentence: 88\n"
     ]
    }
   ],
   "source": [
    "# check length of longest sentence\n",
    "lengths = [len(seq) for seq in X_encoded]\n",
    "print(\"Length of longest sentence: {}\".format(max(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a520e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus tuf\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.boxplot(lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea23519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad each sequence to MAX_SEQ_LENGTH using KERAS' pad_sequences() function. \n",
    "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
    "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
    "\n",
    "# Truncation and padding can either be 'pre' or 'post'. \n",
    "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
    "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
    "\n",
    "MAX_SEQ_LENGTH = 40  # sequences greater than 40 in length will be truncated\n",
    "\n",
    "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"post\")\n",
    "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c9ad205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2106  225    2  765 1195  225    2 2107 2108 2109    2  351 2110  225\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0] \n",
      "\n",
      "\n",
      "\n",
      "[1 7 6 1 1 7 6 1 1 2 6 5 1 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first sequence\n",
    "print(X_padded[0], \"\\n\"*3)\n",
    "print(Y_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47807310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign padded sequences to X and Y\n",
    "X, Y = X_padded, Y_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e7b8b",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "\n",
    "Currently, each word and each tag is encoded as an integer. We'll use a more sophisticated technique to represent the input words (X) using what's known as word embeddings. However, to represent each tag in Y, we'll simply use one-hot encoding scheme since there are only 13 tags in the dataset and the LSTM will have no problems in learning its own representation of these tags. \n",
    "To use word embeddings, you can go for either of the following models:\n",
    "\n",
    "* word2vec model: https://code.google.com/archive/p/word2vec/\n",
    "* GloVe model : https://nlp.stanford.edu/projects/glove/\n",
    "* fasttext : https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "\n",
    "We're using the fastText model because they have pre-trained model for Azerbaijani lanuage. Both of these are very efficient in representing words. You can try both and see which one works better.\n",
    "\n",
    "Dimensions of a word embedding is: (VOCABULARY_SIZE, EMBEDDING_DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19c4cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c9fd648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/PostgresData/cc.az.300.bin'\n",
    "ft = fasttext.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4a59af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7162571549415588, 'daşıKür'),\n",
       " (0.705851137638092, 'daşını'),\n",
       " (0.6851230263710022, 'daşının'),\n",
       " (0.6766510605812073, 'daşını-daş'),\n",
       " (0.6592142581939697, 'daşı-'),\n",
       " (0.6435108184814453, 'daşın'),\n",
       " (0.6427285671234131, 'daşından'),\n",
       " (0.6406784653663635, 'məhək'),\n",
       " (0.6388031840324402, 'daşında'),\n",
       " (0.6243704557418823, 'daşıt')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('daşı')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240bd952",
   "metadata": {},
   "source": [
    "A nice feature is that you can also query for words that did not appear in your data! Indeed words are represented by the sum of its substrings. As long as the unknown word is made of known substrings, there is a representation of it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88aaa6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign word vectors from word2vec model\n",
    "\n",
    "EMBEDDING_SIZE  = 300  # each word in word2vec model is represented using a 300 dimensional vector\n",
    "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "# create an empty embedding matix\n",
    "embedding_weights = np.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))\n",
    "\n",
    "# create a word to index dictionary mapping\n",
    "word2id = word_tokenizer.word_index\n",
    "tag2id = tag_tokenizer.word_index\n",
    "\n",
    "# copy vectors from fasttext model to the words present in corpus\n",
    "for word, index in word2id.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = ft.get_word_vector(word)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b534df2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 1,\n",
       " ',': 2,\n",
       " 'bir': 3,\n",
       " 'və': 4,\n",
       " 'bu': 5,\n",
       " 'ki': 6,\n",
       " 'də': 7,\n",
       " ':': 8,\n",
       " 'mən': 9,\n",
       " 'o': 10,\n",
       " 'da': 11,\n",
       " 'idi': 12,\n",
       " 'sonra': 13,\n",
       " 'ilə': 14,\n",
       " '-': 15,\n",
       " '?': 16,\n",
       " 'kimi': 17,\n",
       " 'onun': 18,\n",
       " 'dedi': 19,\n",
       " 'nə': 20,\n",
       " 'üçün': 21,\n",
       " 'çox': 22,\n",
       " 'şah': 23,\n",
       " 'oğlan': 24,\n",
       " 'isə': 25,\n",
       " 'mənim': 26,\n",
       " 'qədər': 27,\n",
       " 'elə': 28,\n",
       " 'heç': 29,\n",
       " 'mənə': 30,\n",
       " 'var': 31,\n",
       " '!': 32,\n",
       " 'belə': 33,\n",
       " 'qara': 34,\n",
       " 'hər': 35,\n",
       " 'həsən': 36,\n",
       " 'vəzir': 37,\n",
       " 'onu': 38,\n",
       " 'xan': 39,\n",
       " 'öz': 40,\n",
       " 'ona': 41,\n",
       " 'allahverdi': 42,\n",
       " 'olan': 43,\n",
       " 'böyük': 44,\n",
       " 'amma': 45,\n",
       " 'sən': 46,\n",
       " 'nino': 47,\n",
       " 'məni': 48,\n",
       " 'əmim': 49,\n",
       " 'biz': 50,\n",
       " 'qız': 51,\n",
       " 'lakin': 52,\n",
       " 'saat': 53,\n",
       " 'ən': 54,\n",
       " 'gün': 55,\n",
       " 'az': 56,\n",
       " 'dəfə': 57,\n",
       " 'çünki': 58,\n",
       " 'abbas': 59,\n",
       " 'daha': 60,\n",
       " 'olsun': 61,\n",
       " 'bütün': 62,\n",
       " 'yaxşı': 63,\n",
       " 'tutub': 64,\n",
       " 'sağ': 65,\n",
       " 'bokassa': 66,\n",
       " 'sənə': 67,\n",
       " 'görə': 68,\n",
       " 'başladı': 69,\n",
       " 'olub': 70,\n",
       " 'gördüm': 71,\n",
       " 'hüseyn': 72,\n",
       " 'deyə': 73,\n",
       " 'gərək': 74,\n",
       " 'yox': 75,\n",
       " 'dedim': 76,\n",
       " 'biri': 77,\n",
       " 'cavab': 78,\n",
       " 'i̇ndi': 79,\n",
       " 'gözəl': 80,\n",
       " 'adam': 81,\n",
       " 'əgər': 82,\n",
       " 'iki': 83,\n",
       " 'rus': 84,\n",
       " 'verdi': 85,\n",
       " 'necə': 86,\n",
       " 'yerə': 87,\n",
       " 'üç': 88,\n",
       " 'onlar': 89,\n",
       " 'bizim': 90,\n",
       " 'olduğunu': 91,\n",
       " 'ey': 92,\n",
       " 'gəlib': 93,\n",
       " 'yenə': 94,\n",
       " 'onların': 95,\n",
       " 'son': 96,\n",
       " 'gecə': 97,\n",
       " 'gəldi': 98,\n",
       " 'baş': 99,\n",
       " 'edib': 100,\n",
       " 'azərbaycan': 101,\n",
       " 'deyil': 102,\n",
       " 'tay': 103,\n",
       " 'oldu': 104,\n",
       " 'allah': 105,\n",
       " 'orada': 106,\n",
       " 'il': 107,\n",
       " 'ninonun': 108,\n",
       " 'qibleyi-aləm': 109,\n",
       " 'başını': 110,\n",
       " 'sənin': 111,\n",
       " 'gözləri': 112,\n",
       " 'nqi': 113,\n",
       " 'zaman': 114,\n",
       " 'i̇lyas': 115,\n",
       " 'bunu': 116,\n",
       " 'söz': 117,\n",
       " 'vaxt': 118,\n",
       " 'yanına': 119,\n",
       " 'kürd': 120,\n",
       " 'səndən': 121,\n",
       " 'etdi': 122,\n",
       " 'iş': 123,\n",
       " 'ondan': 124,\n",
       " 'düz': 125,\n",
       " 'on': 126,\n",
       " 'ancaq': 127,\n",
       " 'şey': 128,\n",
       " 'hələ': 129,\n",
       " 'başqa': 130,\n",
       " 'olaraq': 131,\n",
       " 'məmməd': 132,\n",
       " 'imtahan': 133,\n",
       " 'xəbər': 134,\n",
       " 'birdən': 135,\n",
       " 'oğlanın': 136,\n",
       " 'içəri': 137,\n",
       " 'tərəfə': 138,\n",
       " 'həmin': 139,\n",
       " 'gedib': 140,\n",
       " 'onları': 141,\n",
       " 'başına': 142,\n",
       " 'atam': 143,\n",
       " 'bizə': 144,\n",
       " 'kişi': 145,\n",
       " 'artıq': 146,\n",
       " 'halda': 147,\n",
       " 'vardı': 148,\n",
       " 'oturub': 149,\n",
       " 'bura': 150,\n",
       " 'verib': 151,\n",
       " 'qoydu': 152,\n",
       " 'getdi': 153,\n",
       " 'əl': 154,\n",
       " 'burada': 155,\n",
       " 'səni': 156,\n",
       " 'yanında': 157,\n",
       " 'yerdə': 158,\n",
       " 'olsa': 159,\n",
       " 'əmr': 160,\n",
       " 'yerinə': 161,\n",
       " 'hamı': 162,\n",
       " 'lazım': 163,\n",
       " 'yalnız': 164,\n",
       " 'qadın': 165,\n",
       " 'bəy': 166,\n",
       " 'bağlı': 167,\n",
       " 'oğlu': 168,\n",
       " 'üzün': 169,\n",
       " 'şəhərə': 170,\n",
       " 'burda': 171,\n",
       " 'çıxıb': 172,\n",
       " 'başı': 173,\n",
       " 'səsi': 174,\n",
       " 'dalınca': 175,\n",
       " 'həramibaşı': 176,\n",
       " 'ol': 177,\n",
       " 'sizin': 178,\n",
       " 'elədi': 179,\n",
       " 'bəli': 180,\n",
       " 'özü': 181,\n",
       " 'barədə': 182,\n",
       " 'bundan': 183,\n",
       " 'su': 184,\n",
       " 'pul': 185,\n",
       " 'qurbağa': 186,\n",
       " 'ilk': 187,\n",
       " 'edirdi': 188,\n",
       " 'olduğu': 189,\n",
       " 'dərəcə': 190,\n",
       " 'cənab': 191,\n",
       " 'eyni': 192,\n",
       " 'hətta': 193,\n",
       " 'şəkildə': 194,\n",
       " 'əmimin': 195,\n",
       " 'idim': 196,\n",
       " 'yemək': 197,\n",
       " 'ayağa': 198,\n",
       " 'durub': 199,\n",
       " 'dünyanın': 200,\n",
       " 'abbasın': 201,\n",
       " 'tərəf': 202,\n",
       " 'gördülər': 203,\n",
       " 'söhbət': 204,\n",
       " 'olar': 205,\n",
       " 'beş': 206,\n",
       " 'başın': 207,\n",
       " 'yeddi': 208,\n",
       " 'qırx': 209,\n",
       " 'axırda': 210,\n",
       " 'əvvəl': 211,\n",
       " 'indi': 212,\n",
       " 'arvad': 213,\n",
       " 'neçə': 214,\n",
       " 'kim': 215,\n",
       " 'yoxdu': 216,\n",
       " 'qala': 217,\n",
       " 'buna': 218,\n",
       " 'tələbə': 219,\n",
       " 'edən': 220,\n",
       " 'əli': 221,\n",
       " 'kiçik': 222,\n",
       " 'yeni': 223,\n",
       " 'uzun': 224,\n",
       " 'içində': 225,\n",
       " 'eləyib': 226,\n",
       " 'üstə': 227,\n",
       " 'qalxıb': 228,\n",
       " 'hərəkət': 229,\n",
       " 'qızı': 230,\n",
       " 'çıxdı': 231,\n",
       " 'hamısı': 232,\n",
       " 'bil': 233,\n",
       " 'görüm': 234,\n",
       " 'bildim': 235,\n",
       " 'gəlirdi': 236,\n",
       " 'eşidən': 237,\n",
       " 'tamam': 238,\n",
       " 'gündən': 239,\n",
       " 'ata': 240,\n",
       " 'oğlunun': 241,\n",
       " 'özümü': 242,\n",
       " 'nyama': 243,\n",
       " 'ruslar': 244,\n",
       " 'ərzində': 245,\n",
       " 'cür': 246,\n",
       " 'incə': 247,\n",
       " 'baxmayaraq': 248,\n",
       " 'gürcü': 249,\n",
       " 'səkkiz': 250,\n",
       " 'ildə': 251,\n",
       " 'film': 252,\n",
       " 'bokassanın': 253,\n",
       " 'xana': 254,\n",
       " 'ya': 255,\n",
       " 'yaşında': 256,\n",
       " 'üstünə': 257,\n",
       " 'getməyə': 258,\n",
       " 'aşağı': 259,\n",
       " 'həmən': 260,\n",
       " 'niyə': 261,\n",
       " 'öldürdüm': 262,\n",
       " 'siz': 263,\n",
       " 'razı': 264,\n",
       " 'allaha': 265,\n",
       " 'onda': 266,\n",
       " 'bəlkə': 267,\n",
       " 'yol': 268,\n",
       " 'atı': 269,\n",
       " 'başladım': 270,\n",
       " 'düşmənimi': 271,\n",
       " 'qalaçaya': 272,\n",
       " 'ikinci': 273,\n",
       " 'yavaş-yavaş': 274,\n",
       " 'dörd': 275,\n",
       " 'ayaq': 276,\n",
       " 'heyvanlar': 277,\n",
       " 'dəhşətli': 278,\n",
       " 'qəribə': 279,\n",
       " 'dəvət': 280,\n",
       " 'şir': 281,\n",
       " 'altında': 282,\n",
       " 'professor': 283,\n",
       " 'şərq': 284,\n",
       " 'etmək': 285,\n",
       " 'şirvanşir': 286,\n",
       " 'dolu': 287,\n",
       " 'arxasında': 288,\n",
       " 'i̇ran': 289,\n",
       " 'bakıya': 290,\n",
       " 'davam': 291,\n",
       " 'verən': 292,\n",
       " 'dövlət': 293,\n",
       " 'zeynal': 294,\n",
       " 'müdirimiz': 295,\n",
       " 'şəhəri': 296,\n",
       " 'abbasla': 297,\n",
       " 'bilmirəm': 298,\n",
       " 'edirlər': 299,\n",
       " 'oğlanı': 300,\n",
       " 'gördü': 301,\n",
       " 'götürüb': 302,\n",
       " 'bilmədi': 303,\n",
       " 'görən': 304,\n",
       " 'atıb': 305,\n",
       " 'qızıl': 306,\n",
       " 'görəndə': 307,\n",
       " 'salıb': 308,\n",
       " 'yoxsa': 309,\n",
       " 'sözləri': 310,\n",
       " 'de': 311,\n",
       " 'arvadları': 312,\n",
       " 'qoca': 313,\n",
       " 'göz': 314,\n",
       " 'doğru': 315,\n",
       " 'ağa': 316,\n",
       " 'bununla': 317,\n",
       " 'pis': 318,\n",
       " 'fikrin': 319,\n",
       " 'verdim': 320,\n",
       " 'idilər': 321,\n",
       " 'bax': 322,\n",
       " 'özünü': 323,\n",
       " 'heyvanların': 324,\n",
       " 'yoxdur': 325,\n",
       " 'balaca': 326,\n",
       " 'görünürdü': 327,\n",
       " 'müsəlman': 328,\n",
       " 'heydər': 329,\n",
       " 'sinifdə': 330,\n",
       " 'bakı': 331,\n",
       " 'orta': 332,\n",
       " 'açıq': 333,\n",
       " 'avropa': 334,\n",
       " 'şəhər': 335,\n",
       " 'bilirdim': 336,\n",
       " 'müdir': 337,\n",
       " 'müəllimimiz': 338,\n",
       " 'türk': 339,\n",
       " 'neft': 340,\n",
       " 'tərəfindən': 341,\n",
       " 'yaşlı': 342,\n",
       " 'çarın': 343,\n",
       " 'çar': 344,\n",
       " 'sinif': 345,\n",
       " 'koronavirus': 346,\n",
       " 'müxtəlif': 347,\n",
       " 'dəstək': 348,\n",
       " 'mədəniyyət': 349,\n",
       " 'təhsil': 350,\n",
       " 'köhnə': 351,\n",
       " 'abbasdan': 352,\n",
       " 'qaldı': 353,\n",
       " 'üstündən': 354,\n",
       " 'işi': 355,\n",
       " 'çəkdi': 356,\n",
       " 'istədi': 357,\n",
       " 'çəkib': 358,\n",
       " 'alıb': 359,\n",
       " 'bunun': 360,\n",
       " 'açıb': 361,\n",
       " 'gələn': 362,\n",
       " 'yaxınlaşdı': 363,\n",
       " 'həmişə': 364,\n",
       " 'geri': 365,\n",
       " 'yola': 366,\n",
       " 'qabağa': 367,\n",
       " 'çoxlu': 368,\n",
       " 'əvvəlcə': 369,\n",
       " 'oldum': 370,\n",
       " 'baxdım': 371,\n",
       " 'elədim': 372,\n",
       " 'bizi': 373,\n",
       " 'etdilər': 374,\n",
       " 'yer': 375,\n",
       " 'soruşdu': 376,\n",
       " 'kəs': 377,\n",
       " 'nədi': 378,\n",
       " 'əlində': 379,\n",
       " 'düşdü': 380,\n",
       " 'atamın': 381,\n",
       " 'istəyirəm': 382,\n",
       " 'olurdu': 383,\n",
       " 'deyib': 384,\n",
       " 'qalmışdı': 385,\n",
       " 'otuz': 386,\n",
       " 'məndən': 387,\n",
       " 'bilər': 388,\n",
       " 'yumşaq': 389,\n",
       " 'lap': 390,\n",
       " 'içinə': 391,\n",
       " 'ağıllı': 392,\n",
       " 'qalmış': 393,\n",
       " 'üçüncü': 394,\n",
       " 'etdim': 395,\n",
       " 'şəhərin': 396,\n",
       " 'nəhayət': 397,\n",
       " 'etdiyi': 398,\n",
       " 'mbaba': 399,\n",
       " 'istifadə': 400,\n",
       " 'edəndə': 401,\n",
       " 'axı': 402,\n",
       " 'arasında': 403,\n",
       " 'elan': 404,\n",
       " 'sanin': 405,\n",
       " 'əlini': 406,\n",
       " 'tərk': 407,\n",
       " 'mavi': 408,\n",
       " 'çadra': 409,\n",
       " 'gimnaziya': 410,\n",
       " 'allahın': 411,\n",
       " 'zamanı': 412,\n",
       " 'üstündə': 413,\n",
       " 'qaranlıq': 414,\n",
       " 'bayır': 415,\n",
       " 'qədim': 416,\n",
       " 'xarici': 417,\n",
       " 'dadaş': 418,\n",
       " 'bəyin': 419,\n",
       " 'ziyafət': 420,\n",
       " 'rəqs': 421,\n",
       " 'qadının': 422,\n",
       " 'insanların': 423,\n",
       " 'knyaz': 424,\n",
       " 'komissiyası': 425,\n",
       " 'qarşı': 426,\n",
       " 'qubernator': 427,\n",
       " 'ölkə': 428,\n",
       " 'prezident': 429,\n",
       " 'dilinin': 430,\n",
       " 'sizə': 431,\n",
       " 'xörək': 432,\n",
       " 'düşdülər': 433,\n",
       " 'yaxınlaşıb': 434,\n",
       " 'xanın': 435,\n",
       " 'xoş': 436,\n",
       " 'qoy': 437,\n",
       " 'gül': 438,\n",
       " 'qızın': 439,\n",
       " 'baxıb': 440,\n",
       " 'xəncəri': 441,\n",
       " 'aldı': 442,\n",
       " 'qılıncı': 443,\n",
       " 'düşüb': 444,\n",
       " 'altı': 445,\n",
       " 'girdi': 446,\n",
       " 'yan': 447,\n",
       " 'gəlir': 448,\n",
       " 'gəldim': 449,\n",
       " 'bağışlayıram': 450,\n",
       " 'üz': 451,\n",
       " 'yüz': 452,\n",
       " 'birini': 453,\n",
       " 'həramilər': 454,\n",
       " 'qılınc': 455,\n",
       " 'and': 456,\n",
       " 'qəbul': 457,\n",
       " 'özün': 458,\n",
       " 'qaldırıb': 459,\n",
       " 'zənən': 460,\n",
       " 'zərif': 461,\n",
       " 'başında': 462,\n",
       " 'əhvalatı': 463,\n",
       " 'şad': 464,\n",
       " 'qapıçı': 465,\n",
       " 'bəri': 466,\n",
       " 'vacib': 467,\n",
       " 'daxil': 468,\n",
       " 'salam': 469,\n",
       " 'demək': 470,\n",
       " 'gülüb': 471,\n",
       " 'işdi': 472,\n",
       " 'yaxın': 473,\n",
       " 'gətirdi': 474,\n",
       " 'qapıda': 475,\n",
       " 'yoldaş': 476,\n",
       " 'quş': 477,\n",
       " 'doğrudan': 478,\n",
       " 'atın': 479,\n",
       " 'getdik': 480,\n",
       " 'özümə': 481,\n",
       " 'düşdüm': 482,\n",
       " 'keçib': 483,\n",
       " 'gedirdi': 484,\n",
       " 'qulaq': 485,\n",
       " 'asan': 486,\n",
       " 'çıxdıq': 487,\n",
       " 'meşənin': 488,\n",
       " 'dünya': 489,\n",
       " 'əsl': 490,\n",
       " 'atları': 491,\n",
       " 'tərəfində': 492,\n",
       " 'nərə': 493,\n",
       " 'tək': 494,\n",
       " 'mümkün': 495,\n",
       " 'qalxdım': 496,\n",
       " 'qalaçanın': 497,\n",
       " 'görüb': 498,\n",
       " 'getdim': 499,\n",
       " 'verir': 500,\n",
       " 'dünyada': 501,\n",
       " 'çatdı': 502,\n",
       " 'dayanıb': 503,\n",
       " 'almaq': 504,\n",
       " 'evə': 505,\n",
       " 'məhv': 506,\n",
       " 'nyamanın': 507,\n",
       " 'quyu': 508,\n",
       " 'əldə': 509,\n",
       " 'daima': 510,\n",
       " 'edir': 511,\n",
       " 'ağ': 512,\n",
       " 'müdrik': 513,\n",
       " 'tısbağa': 514,\n",
       " 'müraciət': 515,\n",
       " 'imkan': 516,\n",
       " 'erməni': 517,\n",
       " 'coğrafi': 518,\n",
       " 'başa': 519,\n",
       " 'boyunca': 520,\n",
       " 'heydərin': 521,\n",
       " 'əsasən': 522,\n",
       " 'qızılı': 523,\n",
       " 'geymiş': 524,\n",
       " 'anda': 525,\n",
       " 'əlimi': 526,\n",
       " 'bakının': 527,\n",
       " 'sona': 528,\n",
       " 'ibarət': 529,\n",
       " 'gümüşü': 530,\n",
       " 'sayəsində': 531,\n",
       " 'məktəbə': 532,\n",
       " 'illər': 533,\n",
       " 'verdiyi': 534,\n",
       " 'etmişdi': 535,\n",
       " 'yay': 536,\n",
       " 'ətrafında': 537,\n",
       " 'çay': 538,\n",
       " 'edirdilər': 539,\n",
       " 'onlara': 540,\n",
       " 'polis': 541,\n",
       " 'üzərinə': 542,\n",
       " 'çariçanın': 543,\n",
       " 'sonralar': 544,\n",
       " 'dərəcədə': 545,\n",
       " 'geniş': 546,\n",
       " 'yüksək': 547,\n",
       " 'hüseynqulu': 548,\n",
       " 'xüsusilə': 549,\n",
       " 'xüsusi': 550,\n",
       " 'saçları': 551,\n",
       " 'din': 552,\n",
       " 'iştirak': 553,\n",
       " 'edərək': 554,\n",
       " 'bildirib': 555,\n",
       " 'səslə': 556,\n",
       " 'hərbi': 557,\n",
       " 'getdikcə': 558,\n",
       " 'salonun': 559,\n",
       " 'cüzamxana': 560,\n",
       " 'sosial': 561,\n",
       " 'tədris': 562,\n",
       " 'ətindən': 563,\n",
       " 'verim': 564,\n",
       " 'çətin': 565,\n",
       " 'i̇sfahan': 566,\n",
       " 'üzünü': 567,\n",
       " 'gəl': 568,\n",
       " 'qabağında': 569,\n",
       " 'deyirsən': 570,\n",
       " 'qəfildən': 571,\n",
       " 'durdu': 572,\n",
       " 'altından': 573,\n",
       " 'razılıq': 574,\n",
       " 'qoyub': 575,\n",
       " 'şəhərdən': 576,\n",
       " 'tərəfdən': 577,\n",
       " 'daşı': 578,\n",
       " 'qapını': 579,\n",
       " 'qalxızıb': 580,\n",
       " 'oğlana': 581,\n",
       " 'tamaşa': 582,\n",
       " 'geyinib': 583,\n",
       " 'qoyun': 584,\n",
       " 'görək': 585,\n",
       " 'vəziri': 586,\n",
       " 'ayrı': 587,\n",
       " 'fikrə': 588,\n",
       " 'bilməz': 589,\n",
       " 'təslim': 590,\n",
       " 'axşam': 591,\n",
       " 'igid': 592,\n",
       " 'olmuşdu': 593,\n",
       " 'oğluna': 594,\n",
       " 'istəyir': 595,\n",
       " 'deyir': 596,\n",
       " 'gətirib': 597,\n",
       " 'özüm': 598,\n",
       " 'işləri': 599,\n",
       " 'izn': 600,\n",
       " 'kəlmə': 601,\n",
       " 'düşmüşdü': 602,\n",
       " 'ev': 603,\n",
       " 'gedə': 604,\n",
       " 'nağıl': 605,\n",
       " 'get': 606,\n",
       " 'atası': 607,\n",
       " 'bilib': 608,\n",
       " 'hörmət': 609,\n",
       " 'istəyirdi': 610,\n",
       " 'ola': 611,\n",
       " 'hamımız': 612,\n",
       " 'çıx': 613,\n",
       " 'hamısını': 614,\n",
       " 'min': 615,\n",
       " 'olmaz': 616,\n",
       " 'çıxdım': 617,\n",
       " 'vəzirlərin': 618,\n",
       " 'fikir': 619,\n",
       " 'qabağıma': 620,\n",
       " 'baxdı': 621,\n",
       " 'vurub': 622,\n",
       " 'etməyib': 623,\n",
       " 'əlimdən': 624,\n",
       " 'atdan': 625,\n",
       " 'haqqında': 626,\n",
       " 'suyu': 627,\n",
       " 'öldürüb': 628,\n",
       " 'irəli': 629,\n",
       " 'əynində': 630,\n",
       " 'ağlına': 631,\n",
       " 'düşmən': 632,\n",
       " 'keçdi': 633,\n",
       " 'i̇kinci': 634,\n",
       " 'gəlmədi': 635,\n",
       " 'yeri': 636,\n",
       " 'səfər': 637,\n",
       " 'qalmışdım': 638,\n",
       " 'versin': 639,\n",
       " 'oğlum': 640,\n",
       " 'hansı': 641,\n",
       " 'şükür': 642,\n",
       " 'vermişdi': 643,\n",
       " 'birinci': 644,\n",
       " 'aldım': 645,\n",
       " 'nəfər': 646,\n",
       " 'etdik': 647,\n",
       " 'quyruq': 648,\n",
       " 'diqqətlə': 649,\n",
       " 'lazımdır': 650,\n",
       " 'quyuya': 651,\n",
       " 'sadəcə': 652,\n",
       " 'rədd': 653,\n",
       " 'tərzdə': 654,\n",
       " 'dünyaya': 655,\n",
       " 'ziyarət': 656,\n",
       " 'dəvəquşu': 657,\n",
       " 'enqudu': 658,\n",
       " 'rəhbəri': 659,\n",
       " 'mbabanı': 660,\n",
       " 'ümumi': 661,\n",
       " 'sizinlə': 662,\n",
       " 'danışmaq': 663,\n",
       " 'bildirdi': 664,\n",
       " '–': 665,\n",
       " 'məgər': 666,\n",
       " 'dırnaqları': 667,\n",
       " 'müqəddəs': 668,\n",
       " 'uyğun': 669,\n",
       " 'iri': 670,\n",
       " 'onlardan': 671,\n",
       " 'coğrafiya': 672,\n",
       " 'şəhərimizin': 673,\n",
       " 'avropanın': 674,\n",
       " 'aid': 675,\n",
       " 'digər': 676,\n",
       " 'inkişaf': 677,\n",
       " 'sual': 678,\n",
       " 'arxa': 679,\n",
       " 'asiyada': 680,\n",
       " 'qalmaq': 681,\n",
       " 'tələbələrə': 682,\n",
       " 'mənasız': 683,\n",
       " 'keçən': 684,\n",
       " 'məsələn': 685,\n",
       " 'yəni': 686,\n",
       " 'i̇randa': 687,\n",
       " 'qaldırdı': 688,\n",
       " 'əti': 689,\n",
       " 'icazə': 690,\n",
       " 'məktəbin': 691,\n",
       " 'tələbələrinin': 692,\n",
       " 'dilində': 693,\n",
       " 'məktəbdə': 694,\n",
       " 'kipiani': 695,\n",
       " 'mənsub': 696,\n",
       " 'gerçəkdən': 697,\n",
       " 'əlləri': 698,\n",
       " 'etmiş': 699,\n",
       " 'i̇mam': 700,\n",
       " 'dili': 701,\n",
       " 'medal': 702,\n",
       " 'məktəblərdə': 703,\n",
       " 'qalırdı': 704,\n",
       " 'həftə': 705,\n",
       " 'evdə': 706,\n",
       " 'bunların': 707,\n",
       " 'buraxılış': 708,\n",
       " 'məzun': 709,\n",
       " 'hiss': 710,\n",
       " 'üstəlik': 711,\n",
       " 'uniforması': 712,\n",
       " 'adi': 713,\n",
       " 'xristian': 714,\n",
       " 'qadınlar': 715,\n",
       " 'ana': 716,\n",
       " 'gəlirdilər': 717,\n",
       " 'kömək': 718,\n",
       " 'münasibət': 719,\n",
       " 'özlərini': 720,\n",
       " 'ipək': 721,\n",
       " 'yorğun': 722,\n",
       " 'malik': 723,\n",
       " 'sifəti': 724,\n",
       " 'sol': 725,\n",
       " 'baxırdı': 726,\n",
       " 'şəhərdə': 727,\n",
       " 'vardır': 728,\n",
       " 'danışmağa': 729,\n",
       " 'xidmətçilər': 730,\n",
       " 'nədən': 731,\n",
       " 'qısa': 732,\n",
       " 'olur': 733,\n",
       " 'knyazın': 734,\n",
       " 'ətrafa': 735,\n",
       " 'çıxmış': 736,\n",
       " 'xoşuna': 737,\n",
       " 'həyata': 738,\n",
       " 'bəzən': 739,\n",
       " 'başlamışdı': 740,\n",
       " 'nəticəsində': 741,\n",
       " 'həyəcanlı': 742,\n",
       " 'riyaziyyat': 743,\n",
       " 'cavablarını': 744,\n",
       " 'sualların': 745,\n",
       " 'müdiri': 746,\n",
       " 'göstərən': 747,\n",
       " 'biletini': 748,\n",
       " 'müəllimin': 749,\n",
       " 'qərb': 750,\n",
       " 'günəşin': 751,\n",
       " 'siyasi': 752,\n",
       " 'ölkədə': 753,\n",
       " 'sahib': 754,\n",
       " 'əlavə': 755,\n",
       " 'qorxu': 756,\n",
       " 'çərçivəsində': 757,\n",
       " 'müvafiq': 758,\n",
       " 'turizm': 759,\n",
       " 'eləcə': 760,\n",
       " 'inkişafına': 761,\n",
       " 'sahibkarlıq': 762,\n",
       " 'kobi̇a': 763,\n",
       " 'məqsədilə': 764,\n",
       " 'qoz': 765,\n",
       " 'atdı': 766,\n",
       " 'mindik': 767,\n",
       " 'i̇ki': 768,\n",
       " 'kimdən': 769,\n",
       " 'xanla': 770,\n",
       " 'eləyirdi': 771,\n",
       " 'işə': 772,\n",
       " 'dur': 773,\n",
       " 'ikisi': 774,\n",
       " 'vəzirlik': 775,\n",
       " 'dəst': 776,\n",
       " 'deyirlər': 777,\n",
       " 'çıxdılar': 778,\n",
       " 'yaxınlaşanda': 779,\n",
       " 'bilirsən': 780,\n",
       " 'heylə': 781,\n",
       " 'yavaşca': 782,\n",
       " 'qulağına': 783,\n",
       " 'çəkilib': 784,\n",
       " 'iyirmi': 785,\n",
       " 'bir-birinə': 786,\n",
       " 'kəsib': 787,\n",
       " 'cəld': 788,\n",
       " 'eləyə': 789,\n",
       " 'özünə': 790,\n",
       " 'evdən': 791,\n",
       " 'dalına': 792,\n",
       " 'başladılar': 793,\n",
       " 'qəbir': 794,\n",
       " 'qəbirin': 795,\n",
       " 'üst': 796,\n",
       " 'açıldı': 797,\n",
       " 'imiş': 798,\n",
       " 'bunlar': 799,\n",
       " 'işıq': 800,\n",
       " 'arasından': 801,\n",
       " 'hərami': 802,\n",
       " 'aparıb': 803,\n",
       " 'dayandı': 804,\n",
       " 'gec': 805,\n",
       " 'bağışla': 806,\n",
       " 'agah': 807,\n",
       " 'fikirləşib': 808,\n",
       " 'qabağına': 809,\n",
       " 'ağlamağa': 810,\n",
       " 'istəmirəm': 811,\n",
       " 'yapışıb': 812,\n",
       " 'gəldilər': 813,\n",
       " 'sabah': 814,\n",
       " 'göndərdi': 815,\n",
       " 'həramilərin': 816,\n",
       " 'məbada': 817,\n",
       " 'kimsən': 818,\n",
       " 'verirəm': 819,\n",
       " 'təvəqqe': 820,\n",
       " 'düzün': 821,\n",
       " 'babamın': 822,\n",
       " 'istəmirdim': 823,\n",
       " 'al': 824,\n",
       " 'yanıma': 825,\n",
       " 'gəlmişdi': 826,\n",
       " 'istədim': 827,\n",
       " 'oğlandı': 828,\n",
       " 'qəbirdən': 829,\n",
       " 'hüzura': 830,\n",
       " 'bilmək': 831,\n",
       " 'adamsan': 832,\n",
       " 'endirib': 833,\n",
       " 'elədilər': 834,\n",
       " 'təyin': 835,\n",
       " 'saxladı': 836,\n",
       " 'tayfası': 837,\n",
       " 'sözü': 838,\n",
       " 'ağır': 839,\n",
       " 'eşidəndə': 840,\n",
       " 'yerində': 841,\n",
       " 'versən': 842,\n",
       " 'evinə': 843,\n",
       " 'qayıtdı': 844,\n",
       " 'yayıldı': 845,\n",
       " 'dağlara': 846,\n",
       " 'bilmirdi': 847,\n",
       " 'eləsin': 848,\n",
       " 'qaraya': 849,\n",
       " 'qaranın': 850,\n",
       " 'at': 851,\n",
       " 'çoban': 852,\n",
       " 'buradan': 853,\n",
       " 'kürdə': 854,\n",
       " 'kürdün': 855,\n",
       " 'əmrini': 856,\n",
       " 'qulluğuna': 857,\n",
       " 'atamı': 858,\n",
       " 'atasının': 859,\n",
       " 'bildi': 860,\n",
       " 'oğul': 861,\n",
       " 'əlindən': 862,\n",
       " 'öpdü': 863,\n",
       " 'lazımi': 864,\n",
       " 'gəlmək': 865,\n",
       " 'görünür': 866,\n",
       " 'şeydən': 867,\n",
       " 'ver': 868,\n",
       " 'görəm': 869,\n",
       " 'olmasa': 870,\n",
       " 'rəhmətlik': 871,\n",
       " 'atanın': 872,\n",
       " 'bilərsən': 873,\n",
       " 'istəyirsən': 874,\n",
       " 'gizlin': 875,\n",
       " 'tutmuş': 876,\n",
       " 'dərin': 877,\n",
       " 'varmı': 878,\n",
       " 'doqquz': 879,\n",
       " 'bərk': 880,\n",
       " 'yerimdən': 881,\n",
       " 'atdım': 882,\n",
       " 'qapıya': 883,\n",
       " 'libasını': 884,\n",
       " 'dava': 885,\n",
       " 'atını': 886,\n",
       " 'atımı': 887,\n",
       " 'hazır': 888,\n",
       " 'qərq': 889,\n",
       " 'üzümü': 890,\n",
       " 'qayıdıb': 891,\n",
       " 'öldürəm': 892,\n",
       " 'şeytan': 893,\n",
       " 'dinməz-söyləməz': 894,\n",
       " 'fikrim': 895,\n",
       " 'keçir': 896,\n",
       " 'gedəndən': 897,\n",
       " 'səs': 898,\n",
       " 'bilirəm': 899,\n",
       " 'ağıl': 900,\n",
       " 'oğlandan': 901,\n",
       " 'versə': 902,\n",
       " 'çatdım': 903,\n",
       " 'açıqlığa': 904,\n",
       " 'ürəyimdə': 905,\n",
       " 'düşmənim': 906,\n",
       " 'almağa': 907,\n",
       " 'şahın': 908,\n",
       " 'adamlar': 909,\n",
       " 'tədbir': 910,\n",
       " 'meşədə': 911,\n",
       " 'gizlənib': 912,\n",
       " 'səhər': 913,\n",
       " 'tezdən': 914,\n",
       " 'kabab': 915,\n",
       " 'tərəfinə': 916,\n",
       " 'gözdən': 917,\n",
       " 'ağzına': 918,\n",
       " 'qalaça': 919,\n",
       " 'görürsən': 920,\n",
       " 'səninlə': 921,\n",
       " 'keçmişdi': 922,\n",
       " 'düşməni': 923,\n",
       " 'başından': 924,\n",
       " 'endi': 925,\n",
       " 'buynuzları': 926,\n",
       " 'heyran': 927,\n",
       " 'sirri': 928,\n",
       " 'möhkəm': 929,\n",
       " 'kəmənddən': 930,\n",
       " 'divarın': 931,\n",
       " 'divara': 932,\n",
       " 'ortasında': 933,\n",
       " 'endim': 934,\n",
       " 'qapısının': 935,\n",
       " 'içi': 936,\n",
       " 'par-par': 937,\n",
       " 'arxayın': 938,\n",
       " 'intiqamını': 939,\n",
       " 'əlimlə': 940,\n",
       " 'çəkdim': 941,\n",
       " 'azad': 942,\n",
       " 'günəş': 943,\n",
       " 'günü': 944,\n",
       " 'tələsik': 945,\n",
       " 'libas': 946,\n",
       " 'keçmiş': 947,\n",
       " 'olmadığı': 948,\n",
       " 'təmiz': 949,\n",
       " 'yanından': 950,\n",
       " 'yollandı': 951,\n",
       " 'quyusuna': 952,\n",
       " 'kəl': 953,\n",
       " 'quruldadı': 954,\n",
       " 'quyusunun': 955,\n",
       " 'suyunu': 956,\n",
       " 'mənəm': 957,\n",
       " 'burdan': 958,\n",
       " 'quruyub': 959,\n",
       " 'çəkir': 960,\n",
       " 'axtarır': 961,\n",
       " 'yada': 962,\n",
       " 'dişləri': 963,\n",
       " 'xeyli': 964,\n",
       " 'quşlar': 965,\n",
       " 'təşkil': 966,\n",
       " 'qanadları': 967,\n",
       " 'engbeme': 968,\n",
       " 'bayram': 969,\n",
       " 'hamını': 970,\n",
       " 'dişlərini': 971,\n",
       " 'donuz': 972,\n",
       " 'buynuz': 973,\n",
       " 'nəhəng': 974,\n",
       " 'ehtiramla': 975,\n",
       " 'insanlar': 976,\n",
       " 'adamların': 977,\n",
       " 'olduğumuz': 978,\n",
       " 'ölüm': 979,\n",
       " 'bakıdakı': 980,\n",
       " 'sektant': 981,\n",
       " 'dərsi': 982,\n",
       " 'sıra': 983,\n",
       " 'xəzər': 984,\n",
       " 'bəzi': 985,\n",
       " 'avropaya': 986,\n",
       " 'olacağını': 987,\n",
       " 'asılıdır': 988,\n",
       " 'birə': 989,\n",
       " 'tələb': 990,\n",
       " 'yerli': 991,\n",
       " 'məktəb': 992,\n",
       " 'dənizi': 993,\n",
       " 'tehranda': 994,\n",
       " 'yolu': 995,\n",
       " 'sinifdən': 996,\n",
       " 'yetdi': 997,\n",
       " 'arxasınca': 998,\n",
       " 'tənəffüsdə': 999,\n",
       " 'qaçıb': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ccb7392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'isim': 1,\n",
       " 'fel': 2,\n",
       " 'durğu_işarəsi': 3,\n",
       " 'əvəzlik': 4,\n",
       " 'sifət': 5,\n",
       " ',': 6,\n",
       " 'zərf': 7,\n",
       " 'bağlayıcı': 8,\n",
       " 'say': 9,\n",
       " 'ədat': 10,\n",
       " 'qoşma': 11,\n",
       " 'hissəcik': 12,\n",
       " '-': 13,\n",
       " 'modal': 14,\n",
       " 'nida': 15}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1647040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.00102859,  0.00347523, -0.02413049, ...,  0.01146229,\n",
       "        -0.02182749,  0.05498237],\n",
       "       [ 0.01508238, -0.09417729, -0.00520617, ...,  0.05473669,\n",
       "         0.02815216, -0.03679167],\n",
       "       ...,\n",
       "       [-0.03868638, -0.04036696,  0.01798723, ...,  0.01122547,\n",
       "         0.00102954, -0.0217728 ],\n",
       "       [ 0.0077829 , -0.00505276,  0.02708293, ..., -0.00563868,\n",
       "        -0.00104441, -0.00371161],\n",
       "       [-0.02288908, -0.05111634, -0.0320226 , ...,  0.07234171,\n",
       "         0.01533616, -0.05874455]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "724037a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (6645, 300)\n"
     ]
    }
   ],
   "source": [
    "# check embedding dimension\n",
    "print(\"Embeddings shape: {}\".format(embedding_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3087b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras' to_categorical function to one-hot encode Y\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee1b0865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74d8ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1806, 40, 16)\n"
     ]
    }
   ],
   "source": [
    "# print Y of the first output sequqnce\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7298bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split entire data into training and testing sets\n",
    "TEST_SIZE = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0e80c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation sets\n",
    "VALID_SIZE = 0.25\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=VALID_SIZE, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "679f67fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Shape of input sequences: (1083, 40)\n",
      "Shape of output sequences: (1083, 40, 16)\n",
      "--------------------------------------------------\n",
      "VALIDATION DATA\n",
      "Shape of input sequences: (361, 40)\n",
      "Shape of output sequences: (361, 40, 16)\n",
      "--------------------------------------------------\n",
      "TESTING DATA\n",
      "Shape of input sequences: (362, 40)\n",
      "Shape of output sequences: (362, 40, 16)\n"
     ]
    }
   ],
   "source": [
    "# print number of samples in each set\n",
    "print(\"TRAINING DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_train.shape))\n",
    "print('Shape of output sequences: {}'.format(Y_train.shape))\n",
    "print(\"-\"*50)\n",
    "print(\"VALIDATION DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_validation.shape))\n",
    "print('Shape of output sequences: {}'.format(Y_validation.shape))\n",
    "print(\"-\"*50)\n",
    "print(\"TESTING DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_test.shape))\n",
    "print('Shape of output sequences: {}'.format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93a1d3",
   "metadata": {},
   "source": [
    "Before using RNN, we must make sure the dimensions of the data are what an RNN expects. In general, an RNN expects the following shape\n",
    "\n",
    "* Shape of X: (#samples, #timesteps, #features)\n",
    "\n",
    "* Shape of Y: (#samples, #timesteps, #features)\n",
    "\n",
    "\n",
    "\n",
    "Now, there can be various variations in the shape that you use to feed an RNN depending on the type of architecture. Since the problem we're working on has a many-to-many architecture, the input and the output both include number of timesteps which is nothing but the sequence length. But notice that the tensor X doesn't have the third dimension, that is, number of features. That's because we're going to use word embeddings before feeding in the data to an RNN, and hence there is no need to explicitly mention the third dimension. That's because when you use the Embedding() layer in Keras, you the training data will automatically be converted to (#samples, #timesteps, #features) where #features will be the embedding dimention (and note that the Embedding layer is always the very first layer of an RNN). While using the embedding layer we only need to reshape the data to (#samples, #timesteps) which is what we have done. However, note that you'll need to shape it to (#samples, #timesteps, #features) in case you don't use the Embedding() layer in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55ddbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=64\n",
    "d=0.5\n",
    "b=5\n",
    "e=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43ebc4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of tags\n",
    "NUM_CLASSES = Y.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59e06c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5fbae",
   "metadata": {},
   "source": [
    "# Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f03315e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        trainable     =  False                    # False - don't update the embeddings\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(l, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fac04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8630b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 300)           1993500   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 40, 64)            23360     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 40, 16)           1040      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,017,900\n",
      "Trainable params: 24,400\n",
      "Non-trainable params: 1,993,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check summary of the model\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77cd8a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "217/217 [==============================] - 2s 5ms/step - loss: 0.7525 - acc: 0.7901 - f1_m: 0.7949 - val_loss: 0.5328 - val_acc: 0.8579 - val_f1_m: 0.8410\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 1s 3ms/step - loss: 0.4780 - acc: 0.8619 - f1_m: 0.8575 - val_loss: 0.4339 - val_acc: 0.8649 - val_f1_m: 0.8709\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 1s 3ms/step - loss: 0.4101 - acc: 0.8705 - f1_m: 0.8710 - val_loss: 0.3915 - val_acc: 0.8755 - val_f1_m: 0.8735\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 1s 3ms/step - loss: 0.3690 - acc: 0.8807 - f1_m: 0.8803 - val_loss: 0.3549 - val_acc: 0.8835 - val_f1_m: 0.8850\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 1s 3ms/step - loss: 0.3357 - acc: 0.8906 - f1_m: 0.8891 - val_loss: 0.3343 - val_acc: 0.8879 - val_f1_m: 0.8901\n"
     ]
    }
   ],
   "source": [
    "rnn_training = rnn_model.fit(X_train, Y_train, batch_size=5, epochs=5, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997e0b9",
   "metadata": {},
   "source": [
    "# 2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8219320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim     = VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                         output_dim    = EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                         input_length  = MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                         weights       = [embedding_weights],     # word embedding matrix\n",
    "                         trainable     = True                     # True - update embeddings_weight matrix\n",
    "))\n",
    "lstm_model.add(LSTM(l, return_sequences=True))\n",
    "lstm_model.add(Dropout(d))\n",
    "lstm_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e6807c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss      =  'categorical_crossentropy',\n",
    "                   optimizer =  'adam',\n",
    "                   metrics   =  ['acc', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e267bdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 40, 300)           1993500   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 40, 64)            93440     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 64)            0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 40, 16)           1040      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,087,980\n",
      "Trainable params: 2,087,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check summary of the model\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70bc7603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "217/217 [==============================] - 4s 15ms/step - loss: 0.7399 - acc: 0.8256 - f1_m: 0.7794 - val_loss: 0.4290 - val_acc: 0.8769 - val_f1_m: 0.8705\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 3s 15ms/step - loss: 0.3351 - acc: 0.9025 - f1_m: 0.9025 - val_loss: 0.2371 - val_acc: 0.9331 - val_f1_m: 0.9320\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 4s 18ms/step - loss: 0.1576 - acc: 0.9566 - f1_m: 0.9585 - val_loss: 0.1636 - val_acc: 0.9555 - val_f1_m: 0.9527\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 4s 18ms/step - loss: 0.0854 - acc: 0.9788 - f1_m: 0.9771 - val_loss: 0.1423 - val_acc: 0.9611 - val_f1_m: 0.9587\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 4s 18ms/step - loss: 0.0579 - acc: 0.9860 - f1_m: 0.9844 - val_loss: 0.1329 - val_acc: 0.9617 - val_f1_m: 0.9614\n"
     ]
    }
   ],
   "source": [
    "lstm_training = lstm_model.fit(X_train, Y_train, batch_size=5, epochs=5, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "525f9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create architecture\n",
    "\n",
    "# rnn_model = Sequential()\n",
    "\n",
    "# # create embedding layer - usually the first layer in text problems\n",
    "# rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "#                         output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "#                         input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "#                         trainable     =  True                     # True - update the embeddings while training\n",
    "# ))\n",
    "l=8\n",
    "d=0.65\n",
    "# # add an RNN layer which contains 64 RNN cells\n",
    "# rnn_model.add(SimpleRNN(64, \n",
    "#               return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "# ))\n",
    "\n",
    "# # add time distributed (output at each sequence) layer\n",
    "# rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "03cede88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "#                   optimizer =  'adam',\n",
    "#                   metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5dc52",
   "metadata": {},
   "source": [
    "# 3. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d7a42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(input_dim     = VOCABULARY_SIZE,\n",
    "                        output_dim    = EMBEDDING_SIZE,\n",
    "                        input_length  = MAX_SEQ_LENGTH,\n",
    "                        weights       = [embedding_weights],\n",
    "                        trainable     = True\n",
    "))\n",
    "gru_model.add(GRU(l, return_sequences=True))\n",
    "gru_model.add(Dropout(d))\n",
    "gru_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "66bd2775",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8c68e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 40, 300)           1993500   \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 40, 8)             7440      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 40, 8)             0         \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 40, 16)           144       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,001,084\n",
      "Trainable params: 2,001,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check summary of model\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8fdd8aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "217/217 [==============================] - 5s 18ms/step - loss: 1.4290 - acc: 0.6612 - f1_m: 0.4793 - val_loss: 0.6861 - val_acc: 0.8332 - val_f1_m: 0.8421\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.8224 - acc: 0.8111 - f1_m: 0.7508 - val_loss: 0.4760 - val_acc: 0.9098 - val_f1_m: 0.8421\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.6463 - acc: 0.8265 - f1_m: 0.7968 - val_loss: 0.3713 - val_acc: 0.9332 - val_f1_m: 0.8910\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 4s 18ms/step - loss: 0.5465 - acc: 0.8412 - f1_m: 0.8366 - val_loss: 0.3114 - val_acc: 0.9400 - val_f1_m: 0.9119\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 4s 18ms/step - loss: 0.4879 - acc: 0.8523 - f1_m: 0.8541 - val_loss: 0.2704 - val_acc: 0.9474 - val_f1_m: 0.9241\n"
     ]
    }
   ],
   "source": [
    "gru_training = gru_model.fit(X_train, Y_train, batch_size=5, epochs=5, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff962cdb",
   "metadata": {},
   "source": [
    "# 5. Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "613d11a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3390 - acc: 0.8854 - f1_m: 0.8889\n"
     ]
    }
   ],
   "source": [
    "rnn_64_loss, rnn_64_accuracy, rnn_64_f1_score = rnn_model.evaluate(X_test, Y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eefead63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1310 - acc: 0.9627 - f1_m: 0.9604\n"
     ]
    }
   ],
   "source": [
    "lstm_64_loss, lstm_64_accuracy, lstm_64_f1_score = lstm_model.evaluate(X_test, Y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ad047c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2739 - acc: 0.9490 - f1_m: 0.9220\n"
     ]
    }
   ],
   "source": [
    "gru_64_loss, gru_64_accuracy, gru_64_f1_score = gru_model.evaluate(X_test, Y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "504ce72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rnn_training.history['f1_m'])\n",
    "plt.plot(lstm_training.history['f1_m'])\n",
    "plt.plot(gru_training.history['f1_m'])\n",
    "plt.title('F1 score for Azerbaijani with 64 layer')\n",
    "plt.ylabel('F1_Measurement')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['rnn', 'lstm', 'gru'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b10e966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_64_training_f1 = rnn_training.history['val_f1_m']\n",
    "lstm_64_training_f1 = lstm_training.history['val_f1_m']\n",
    "gru_64_training_f1 = gru_training.history['val_f1_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec5edaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'rnn_64_training_f1' (list)\n",
      "Stored 'lstm_64_training_f1' (list)\n",
      "Stored 'gru_64_training_f1' (list)\n"
     ]
    }
   ],
   "source": [
    "%store rnn_64_training_f1\n",
    "%store lstm_64_training_f1\n",
    "%store gru_64_training_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bfd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
